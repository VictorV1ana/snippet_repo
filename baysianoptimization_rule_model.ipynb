{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPluVqlzLDp4pL8oABfl1x9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorV1ana/snippet_repo/blob/main/baysianoptimization_rule_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOSJuTOlcBU5"
      },
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianOptimization:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def custom_method(self, param1, param2):\n",
        "        qtd_total_movimentada = self.X[:, 0]\n",
        "        ratio = self.X[:, 1]\n",
        "\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[qtd_total_movimentada >= param1] += 1\n",
        "        result[ratio >= param2] += 1\n",
        "\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, y_true, y_pred):\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)\n",
        "\n",
        "    def objective_function(self, params):\n",
        "        params['param1'] = int(params['param1'])\n",
        "        params['param2'] = int(params['param2'])\n",
        "\n",
        "        y_pred = self.custom_method(params['param1'], params['param2'])\n",
        "        score = self.custom_metric(self.y, y_pred)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        param_space = {'param1': (1, 10), 'param2': (0, 1)}\n",
        "\n",
        "        opt = BayesSearchCV(None, param_space, n_iter=50, n_jobs=-1, scoring=self.custom_metric, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
        "        opt.fit(self.X, self.y)\n",
        "\n",
        "        return opt\n",
        "\n",
        "    def visualize_results(self, opt):\n",
        "        results = opt.cv_results_\n",
        "        plt.scatter(results['param_param1'], results['param_param2'], c=results['mean_test_score'], cmap='viridis', s=50)\n",
        "        plt.colorbar(label='Mean of the custom metric')\n",
        "        plt.xlabel('param1')\n",
        "        plt.ylabel('param2')\n",
        "        plt.title('Bayesian Optimization - Top 5 combinations')\n",
        "        plt.show()\n",
        "\n",
        "# Example usage:\n",
        "X_train = np.array([[10, 0.5], [15, 0.8], [5, 0.3]])\n",
        "y_train = np.array([1, 0, 1])\n",
        "\n",
        "optimizer = BayesianOptimization(X_train, y_train)\n",
        "optimal_params = optimizer.optimize_parameters()\n",
        "\n",
        "print(\"Top 5 combinations:\")\n",
        "for i, params in enumerate(optimal_params.cv_results_['params']):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    print(f\"Combination {i+1}: {params}\")\n",
        "\n",
        "optimizer.visualize_results(optimal_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianRuleOptimization:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def apply_rules(self, params):\n",
        "        # Substitua esta função com suas próprias regras baseadas em parâmetros\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[self.X[:, 0] >= params[0]] += 1\n",
        "        result[self.X[:, 1] >= params[1]] += 1\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, params):\n",
        "        y_pred = self.apply_rules(params)\n",
        "        tp = np.sum((self.y == 1) & (y_pred == 1))\n",
        "        fp = np.sum((self.y == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)  # Objetivo é maximizar a métrica\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        result = minimize(lambda params: -self.custom_metric(params), x0=[1, 0.5], bounds=[(1, 10), (0, 1)])\n",
        "        return result\n",
        "\n",
        "    def visualize_results(self, result):\n",
        "        plt.scatter(result.x[0], result.x[1], c=self.custom_metric(result.x), cmap='viridis', s=100, marker='X')\n",
        "        plt.colorbar(label='Mean of the custom metric')\n",
        "        plt.xlabel('param1')\n",
        "        plt.ylabel('param2')\n",
        "        plt.title('Bayesian Optimization - Best Combination')\n",
        "        plt.show()\n",
        "\n",
        "# Example usage:\n",
        "X_train = np.array([[10, 0.5], [15, 0.8], [5, 0.3]])\n",
        "y_train = np.array([1, 0, 1])\n",
        "\n",
        "optimizer = BayesianRuleOptimization(X_train, y_train)\n",
        "optimal_result = optimizer.optimize_parameters()\n",
        "\n",
        "print(\"Best combination:\", optimal_result.x)\n",
        "optimizer.visualize_results(optimal_result)\n"
      ],
      "metadata": {
        "id": "vu2r2xY1XkMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianRuleOptimizationOptuna:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def apply_rules(self, param1, param2):\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[self.X[:, 0] >= param1] += 1\n",
        "        result[self.X[:, 1] >= param2] += 1\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, trial):\n",
        "        param1 = trial.suggest_float('param1', 1, 10)\n",
        "        param2 = trial.suggest_float('param2', 0, 1)\n",
        "\n",
        "        y_pred = self.apply_rules(param1, param2)\n",
        "        tp = np.sum((self.y == 1) & (y_pred == 1))\n",
        "        fp = np.sum((self.y == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.custom_metric, n_trials=50)\n",
        "        return study\n",
        "\n",
        "    def visualize_results(self, study):\n",
        "        optuna.visualization.plot_contour(study, params=['param1', 'param2'])\n",
        "        plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "X_train = np.array([[10, 0.5], [15, 0.8], [5, 0.3]])\n",
        "y_train = np.array([1, 0, 1])\n",
        "\n",
        "optimizer_optuna = BayesianRuleOptimizationOptuna(X_train, y_train)\n",
        "optimal_study = optimizer_optuna.optimize_parameters()\n",
        "\n",
        "print(\"Best combination:\", optimal_study.best_params)\n",
        "optimizer_optuna.visualize_results(optimal_study)\n"
      ],
      "metadata": {
        "id": "LBLU6JCeXle3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianRuleOptimizationOptuna:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def apply_rules(self, param1, param2):\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[self.X[:, 0] >= param1] += 1\n",
        "        result[self.X[:, 1] >= param2] += 1\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, trial):\n",
        "        param1 = trial.suggest_float('param1', 1, 10)\n",
        "        param2 = trial.suggest_float('param2', 0, 1)\n",
        "\n",
        "        y_pred = self.apply_rules(param1, param2)\n",
        "        tp = np.sum((self.y == 1) & (y_pred == 1))\n",
        "        fp = np.sum((self.y == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.custom_metric, n_trials=50)\n",
        "        return study\n",
        "\n",
        "    def visualize_results(self, study):\n",
        "        optuna.visualization.plot_contour(study, params=['param1', 'param2'])\n",
        "        plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "X_train = np.array([[10, 0.5], [15, 0.8], [5, 0.3]])\n",
        "y_train = np.array([1, 0, 1])\n",
        "\n",
        "optimizer_optuna = BayesianRuleOptimizationOptuna(X_train, y_train)\n",
        "optimal_study = optimizer_optuna.optimize_parameters()\n",
        "\n",
        "print(\"Best combination:\", optimal_study.best_params)\n",
        "optimizer_optuna.visualize_results(optimal_study)\n"
      ],
      "metadata": {
        "id": "eYove3J1XpCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc3 as pm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianRuleOptimizationPyMC3WithNormals:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def apply_rules(self, param1, param2):\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[self.X[:, 0] >= param1] += 1\n",
        "        result[self.X[:, 1] >= param2] += 1\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, params):\n",
        "        param1, param2 = params[0], params[1]\n",
        "        y_pred = self.apply_rules(param1, param2)\n",
        "        tp = np.sum((self.y == 1) & (y_pred == 1))\n",
        "        fp = np.sum((self.y == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        with pm.Model() as model:\n",
        "            param1 = pm.Uniform('param1', lower=1, upper=10)\n",
        "            param2 = pm.Uniform('param2', lower=0, upper=1)\n",
        "\n",
        "            prior_param1 = pm.Normal('prior_param1', mu=5, sd=2)\n",
        "            prior_param2 = pm.Normal('prior_param2', mu=0.5, sd=0.2)\n",
        "\n",
        "            likelihood = pm.DensityDist('likelihood', self.custom_metric, observed={'params': [param1, param2]})\n",
        "\n",
        "            trace = pm.sample(50, tune=20, cores=1, random_seed=42)\n",
        "\n",
        "        return trace\n",
        "\n",
        "    def find_best_params(self, trace):\n",
        "        index_max_metric = np.argmax(trace['likelihood'])\n",
        "        best_params = {'param1': trace['param1'][index_max_metric],\n",
        "                       'param2': trace['param2'][index_max_metric]}\n",
        "        return best_params\n",
        "\n",
        "    def visualize_results(self, trace):\n",
        "        pm.traceplot(trace)\n",
        "        plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "X_train = np.array([[10, 0.5], [15, 0.8], [5, 0.3]])\n",
        "y_train = np.array([1, 0, 1])\n",
        "\n",
        "optimizer_pymc3_normals = BayesianRuleOptimizationPyMC3WithNormals(X_train, y_train)\n",
        "optimal_trace_normals = optimizer_pymc3_normals.optimize_parameters()\n",
        "\n",
        "best_params_normals = optimizer_pymc3_normals.find_best_params(optimal_trace_normals)\n",
        "print(\"Best parameters:\", best_params_normals)\n",
        "optimizer_pymc3_normals.visualize_results(optimal_trace_normals)\n"
      ],
      "metadata": {
        "id": "wdCapixNXse4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc3 as pm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianRuleOptimizationPyMC3WithLogNormals:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def apply_rules(self, param1, param2):\n",
        "        result = np.zeros(len(self.X), dtype=int)\n",
        "        result[self.X[:, 0] >= param1] += 1\n",
        "        result[self.X[:, 1] >= param2] += 1\n",
        "        return result\n",
        "\n",
        "    def custom_metric(self, params):\n",
        "        param1, param2 = params[0], params[1]\n",
        "        y_pred = self.apply_rules(param1, param2)\n",
        "        tp = np.sum((self.y == 1) & (y_pred == 1))\n",
        "        fp = np.sum((self.y == 0) & (y_pred == 1))\n",
        "        return tp / (tp + fp)\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        with pm\n"
      ],
      "metadata": {
        "id": "5_Ad8dciXx-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}